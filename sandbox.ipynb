{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGL Tutorial Sandbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import dgl.data\n",
    "import dgl\n",
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False])}\n",
      "{}\n",
      "tensor([ True,  True,  True,  ..., False, False, False])\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "tensor([False, False, False,  ...,  True,  True,  True])\n",
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "g = dataset[0]  # a dgl dataset object may contain one or multiple graphs\n",
    "print(g.ndata)  # node features\n",
    "print(g.edata)  # edge features\n",
    "print(g.ndata['train_mask'])  # the training set mask\n",
    "print(g.ndata['val_mask'])  # the validation set mask\n",
    "print(g.ndata['test_mask'])  # the test set mask\n",
    "print(g.ndata['label'])  # the ground truth labels\n",
    "print(g.ndata['feat'])  # the node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708\n",
      "10556\n",
      "(tensor([   0,    0,    0,  ..., 2707, 2707, 2707]), tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]))\n",
      "torch.Size([2708])\n"
     ]
    }
   ],
   "source": [
    "g.ndata['feat'].shape\n",
    "print(g.number_of_nodes())\n",
    "print(g.number_of_edges())\n",
    "print(g.edges())\n",
    "print(g.nodes().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.946, val acc: 0.128 (best 0.128), test acc: 0.100 (best 0.100)\n",
      "In epoch 1, loss: 1.941, val acc: 0.176 (best 0.176), test acc: 0.160 (best 0.160)\n",
      "In epoch 2, loss: 1.932, val acc: 0.228 (best 0.228), test acc: 0.245 (best 0.245)\n",
      "In epoch 3, loss: 1.923, val acc: 0.410 (best 0.410), test acc: 0.411 (best 0.411)\n",
      "In epoch 4, loss: 1.914, val acc: 0.456 (best 0.456), test acc: 0.467 (best 0.467)\n",
      "In epoch 5, loss: 1.902, val acc: 0.534 (best 0.534), test acc: 0.539 (best 0.539)\n",
      "In epoch 6, loss: 1.889, val acc: 0.602 (best 0.602), test acc: 0.605 (best 0.605)\n",
      "In epoch 7, loss: 1.875, val acc: 0.628 (best 0.628), test acc: 0.625 (best 0.625)\n",
      "In epoch 8, loss: 1.861, val acc: 0.628 (best 0.628), test acc: 0.630 (best 0.625)\n",
      "In epoch 9, loss: 1.845, val acc: 0.640 (best 0.640), test acc: 0.649 (best 0.649)\n"
     ]
    }
   ],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "\n",
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "\n",
    "    for e in range(10):\n",
    "        # forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # compute loss; Note that we use the mask to filter out invalid entries in the label tensor\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            'In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "model = GCN(\n",
    "    g.ndata['feat'].shape[1], 16, dataset.num_classes\n",
    ")  # input feature size, hidden size, output feature size\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./interactions.csv', <http.client.HTTPMessage at 0x7fbce10aba60>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://data.dgl.ai/tutorial/dataset/members.csv\", \"./members.csv\"\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://data.dgl.ai/tutorial/dataset/interactions.csv\",\n",
    "    \"./interactions.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Club</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Club  Age\n",
       "0   0  Mr. Hi   44\n",
       "1   1  Mr. Hi   37\n",
       "2   2  Mr. Hi   37\n",
       "3   3  Mr. Hi   40\n",
       "4   4  Mr. Hi   30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = pd.read_csv(\"./members.csv\")\n",
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Dst</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.282119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.370293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.730570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.821187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Src  Dst    Weight\n",
       "0    0    1  0.043591\n",
       "1    0    2  0.282119\n",
       "2    0    3  0.370293\n",
       "3    0    4  0.730570\n",
       "4    0    5  0.821187"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = pd.read_csv(\"./interactions.csv\")\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import dgl\n",
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8b/k5324nqs2fz6jhh0ntj6lz_r0000gn/T/ipykernel_37993/2356754960.py:15: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  node_labels = torch.from_numpy(\n"
     ]
    }
   ],
   "source": [
    "# treats the members as nodes and interactions as edges.\n",
    "# It takes age as a numerical feature of the nodes,\n",
    "# affiliated club as the label of the nodes, and\n",
    "# edge weight as a numerical feature of the edges.\n",
    "\n",
    "\n",
    "class KarateClubDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"karate_club\")\n",
    "\n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv(\"./members.csv\")\n",
    "        edges_data = pd.read_csv(\"./interactions.csv\")\n",
    "        node_features = torch.from_numpy(nodes_data[\"Age\"].to_numpy())\n",
    "        node_labels = torch.from_numpy(\n",
    "            nodes_data[\"Club\"].astype(\"category\").cat.codes.to_numpy()\n",
    "        )\n",
    "\n",
    "        # save the mapping rule from label id to raw labels\n",
    "        mapping_rule = dict(\n",
    "            zip(nodes_data[\"Club\"].astype(\"category\").cat.codes, nodes_data[\"Club\"])\n",
    "        )\n",
    "        torch.save(mapping_rule, \"mapping_rule.pt\")\n",
    "\n",
    "        edge_features = torch.from_numpy(edges_data[\"Weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data[\"Src\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data[\"Dst\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # assign masks indicating whether a node/edge belongs to training/validation/test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "dataset = KarateClubDataset()\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Mr. Hi', 1: 'Officer'}\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = torch.load(\"mapping_rule.pt\")\n",
    "print(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Hi'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [mapping_dict[int(label)] for label in graph.ndata['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Officer',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Mr. Hi',\n",
       " 'Mr. Hi',\n",
       " 'Officer',\n",
       " 'Mr. Hi',\n",
       " 'Officer',\n",
       " 'Mr. Hi',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer',\n",
       " 'Officer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=34, num_edges=156,\n",
       "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = dataset[0]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[34], edge_index=[2, 156], y=[34], train_mask=[34], val_mask=[34], test_mask=[34])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
      "          3,  3,  3,  3,  3,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,\n",
      "          7,  7,  8,  8,  8,  8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 13,\n",
      "         13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 20, 21,\n",
      "         21, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27,\n",
      "         27, 27, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31, 31,\n",
      "         31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,\n",
      "         33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  0,  2,\n",
      "          3,  7, 13, 17, 19, 21, 30,  0,  1,  3,  7,  8,  9, 13, 27, 28, 32,  0,\n",
      "          1,  2,  7, 12, 13,  0,  6, 10,  0,  6, 10, 16,  0,  4,  5, 16,  0,  1,\n",
      "          2,  3,  0,  2, 30, 32, 33,  2, 33,  0,  4,  5,  0,  0,  3,  0,  1,  2,\n",
      "          3, 33, 32, 33, 32, 33,  5,  6,  0,  1, 32, 33,  0,  1, 33, 32, 33,  0,\n",
      "          1, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 23, 24, 31, 29, 33,  2, 23,\n",
      "         24, 33,  2, 31, 33, 23, 26, 32, 33,  1,  8, 32, 33,  0, 24, 25, 28, 32,\n",
      "         33,  2,  8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 33,  8,  9, 13, 14, 15,\n",
      "         18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset = Data(\n",
    "    x=g.ndata['feat'],\n",
    "    edge_index=torch.stack(g.edges()),\n",
    "    y=g.ndata['label'],\n",
    "    train_mask=g.ndata['train_mask'],\n",
    "    val_mask=g.ndata['val_mask'],\n",
    "    test_mask=g.ndata['test_mask'],\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import DGLDataset\n",
    "\n",
    "\n",
    "class MyDataset(DGLDataset):\n",
    "    \"\"\"Template for customizing graph datasets in DGL.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to download the raw dataset\n",
    "    raw_dir : str\n",
    "        Specifying the directory that will store the\n",
    "        downloaded data or the directory that\n",
    "        already stores the input data.\n",
    "        Default: ~/.dgl/\n",
    "    save_dir : str\n",
    "        Directory to save the processed dataset.\n",
    "        Default: the value of `raw_dir`\n",
    "    force_reload : bool\n",
    "        Whether to reload the dataset. Default: False\n",
    "    verbose : bool\n",
    "        Whether to print out progress information\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, url=None, raw_dir=None, save_dir=None, force_reload=False, verbose=False\n",
    "    ):\n",
    "        super(MyDataset, self).__init__(\n",
    "            name='dataset_name',\n",
    "            url=url,\n",
    "            raw_dir=raw_dir,\n",
    "            save_dir=save_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "    def download(self):\n",
    "        # download raw data to local disk\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # process raw data to graphs, labels, splitting masks\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get one example by index\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        # number of data examples\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        # save processed data to directory `self.save_path`\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        # load processed data from directory `self.save_path`\n",
    "        pass\n",
    "\n",
    "    def has_cache(self):\n",
    "        # check whether there are processed data in `self.save_path`\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minigpt4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
